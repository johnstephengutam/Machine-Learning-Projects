{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15f8c1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johns\\anaconda3\\envs\\cs688\\lib\\site-packages\\ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\johns\\anaconda3\\envs\\cs688\\lib\\site-packages\\ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in multiply\n",
      "C:\\Users\\johns\\anaconda3\\envs\\cs688\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy error on training set: nan\n",
      "Classification error on training set: 1.0\n",
      "Classification error on test set: 1.0\n",
      "Training time: 1.092109203338623 seconds\n",
      "Cross-entropy error on training set: nan\n",
      "Classification error on training set: 1.0\n",
      "Classification error on test set: 1.0\n",
      "Training time: 1.0475528240203857 seconds\n",
      "Cross-entropy error on training set: nan\n",
      "Classification error on training set: 1.0\n",
      "Classification error on test set: 1.0\n",
      "Training time: 1.1635668277740479 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_regression_gradient_descent(X, y, learning_rate=1e-5, max_iterations=10000, gradient_threshold=1e-6):\n",
    "    \"\"\"logistic regression model using gradient descent.\"\"\"\n",
    "    # Initialize weights with random values\n",
    "    np.random.seed(0)\n",
    "    num_features = X.shape[1]\n",
    "    w = np.random.randn(num_features + 1)  # Include intercept term\n",
    "\n",
    "    # Add intercept term to features\n",
    "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "    # Initialize variables for error metrics\n",
    "    errors = []\n",
    "\n",
    "    # Perform gradient descent\n",
    "    start_time = time.time()\n",
    "    for i in range(max_iterations):\n",
    "        # Compute predictions\n",
    "        z = np.dot(X, w)\n",
    "        y_pred = sigmoid(z)\n",
    "\n",
    "        # Compute gradients\n",
    "        gradient = np.dot(X.T, y - y_pred)\n",
    "\n",
    "        # Update weights\n",
    "        w += learning_rate * gradient\n",
    "\n",
    "        # Compute cross-entropy error\n",
    "        cross_entropy_error = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "        errors.append(cross_entropy_error)\n",
    "\n",
    "        # Check gradient magnitude for termination\n",
    "        if np.all(np.abs(gradient) < gradient_threshold):\n",
    "            break\n",
    "\n",
    "    # Compute classification error on training set\n",
    "    y_pred_binary = np.round(y_pred)\n",
    "    classification_error = np.mean(y_pred_binary != y)\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    return w, errors[-1], classification_error, training_time\n",
    "\n",
    "\n",
    "# Load the Cleveland dataset\n",
    "url_train = \"cleveland-train.csv\"\n",
    "url_test = \"cleveland-test.csv\"\n",
    "\n",
    "# Load the training dataset\n",
    "df_train = pd.read_csv(url_train)\n",
    "X_train = df_train.iloc[:, :-1].values\n",
    "y_train = df_train.iloc[:, -1].values\n",
    "\n",
    "# Load the test dataset\n",
    "df_test = pd.read_csv(url_test)\n",
    "X_test = df_test.iloc[:, :-1].values\n",
    "y_test = df_test.iloc[:, -1].values\n",
    "\n",
    "# Run experiments\n",
    "for max_iterations in [10000, 100000, 1000000]:\n",
    "    # Train logistic regression model using gradient descent\n",
    "    w, cross_entropy_error, classification_error, training_time = logistic_regression_gradient_descent(X_train, y_train, max_iterations)\n",
    "\n",
    "    # Evaluate model on test set\n",
    "    X_test_with_intercept = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "    z_test = np.dot(X_test_with_intercept, w)\n",
    "    y_pred_test = sigmoid(z_test)\n",
    "    y_pred_test_binary = np.round(y_pred_test)\n",
    "    test_classification_error = np.mean(y_pred_test_binary != y_test)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Cross-entropy error on training set: {cross_entropy_error}\")\n",
    "    print(f\"Classification error on training set: {classification_error}\")\n",
    "    print(f\"Classification error on test set: {test_classification_error}\")\n",
    "    print(f\"Training time: {training_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf798cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
